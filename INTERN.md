# INTERN.md - NurÅŸen Akay

## Proje Ã–zeti

Bu proje, kullanÄ±cÄ±larÄ±n **doÄŸal dil** kullanarak uygulama konfigÃ¼rasyonlarÄ±nÄ± gÃ¼ncellemesini saÄŸlayan **AI destekli bir sistem**dir. Sistem, JSON ÅŸemalarÄ±nÄ± ve deÄŸerleri yÃ¶neten 3 mikroservis ve bir AI modeli kullanÄ±r.

---

## Mimari Kararlar

### 1. Mikroservis Mimarisi

**Neden 3 ayrÄ± servis?**
- **Separation of Concerns**: Her servis tek bir iÅŸten sorumlu
- **Ã–lÃ§eklenebilirlik**: Servisleri baÄŸÄ±msÄ±z olarak Ã¶lÃ§eklendirilebilir
- **BakÄ±m kolaylÄ±ÄŸÄ±**: Bir serviste sorun olduÄŸunda diÄŸerleri etkilenmez
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KullanÄ±cÄ±  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Bot Service    â”‚ (5003)
â”‚   (AI-powered)   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
â”‚        â”‚
â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Schema  â”‚ â”‚ Values  â”‚
â”‚ Service â”‚ â”‚ Service â”‚
â”‚ (5001)  â”‚ â”‚ (5002)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
---

### 2. AI Model SeÃ§imi: Llama 3.2 (3B)

**Neden Llama 3.2:3b?**

âœ… **Avantajlar:**
- **Hafif**: 3 milyar parametre - lokal makinelerde hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r
- **JSON desteÄŸi**: Structured output iÃ§in optimize edilmiÅŸ
- **HÄ±zlÄ± inference**: ~2-3 saniyede yanÄ±t verir
- **Ollama desteÄŸi**: Kolay kurulum ve kullanÄ±m

âŒ **Alternatifler ve neden seÃ§ilmedi:**
- **Llama 3.1 (8B/70B)**: Ã‡ok aÄŸÄ±r, local ortamda yavaÅŸ
- **Mistral**: JSON formatÄ±nda tutarsÄ±z yanÄ±tlar
- **Gemma**: KonfigÃ¼rasyon gÃ¼ncellemelerinde daha az tutarlÄ±

---

### 3. Ä°ki AÅŸamalÄ± AI SÃ¼reci

**Neden iki ayrÄ± AI Ã§aÄŸrÄ±sÄ±?**

1. **Ä°lk Ã§aÄŸrÄ±**: Uygulama adÄ±nÄ± tespit et
   - Girdi: Sadece kullanÄ±cÄ± mesajÄ±
   - Ã‡Ä±ktÄ±: `{"app_name": "chat"}`
   - **Neden ayrÄ±?** Schema ve values Ã§ok bÃ¼yÃ¼k (100KB+), gereksiz yere token harcamayÄ± Ã¶nler

2. **Ä°kinci Ã§aÄŸrÄ±**: DeÄŸerleri gÃ¼ncelle
   - Girdi: KullanÄ±cÄ± mesajÄ± + Schema + Mevcut deÄŸerler
   - Ã‡Ä±ktÄ±: GÃ¼ncellenmiÅŸ JSON
   - **Neden ayrÄ±?** AI sadece gerekli uygulama iÃ§in schema yÃ¼kler, daha hÄ±zlÄ± ve doÄŸru

---

### 4. Prompt Engineering Stratejisi

**JSON formatÄ±nÄ± garanti altÄ±na almak iÃ§in:**
```python
prompt = """
Respond ONLY with a JSON object in this exact format:
{"app_name": "identified_app_name"}
"""
```

**Neden Ã¶nemli?**
- AI'lar bazen aÃ§Ä±klama ekler: "Sure, here is the JSON..."
- Strict format sayesinde `json.loads()` baÅŸarÄ±lÄ± olur
- Hata yÃ¶netimi iÃ§in fallback mekanizmasÄ± var

---

### 5. Hata YÃ¶netimi ve Fallback

**AI baÅŸarÄ±sÄ±z olursa ne olur?**
```python
# Fallback: Basit anahtar kelime eÅŸleÅŸtirme
if "tournament" in user_input.lower():
    return "tournament"
`**Neden gerekli?**
- AI modelleri %100 garantili deÄŸil
- Network sorunlarÄ± olabilir
- Basit istekler iÃ§in AI gereksiz

---

## Sistem AkÄ±ÅŸÄ± (End-to-End)

### Ã–rnek: "set tournament service memory to 1024mb"
```
1. KullanÄ±cÄ± â†’ Bot Service (POST /message)
   Input: {"input": "set tournament service memory to 1024mb"}

2. Bot Service â†’ Ollama AI
   "Hangi uygulama?"
   â† "tournament"

3. Bot Service â†’ Schema Service (GET /tournament)
   â† tournament.schema.json (68KB)

4. Bot Service â†’ Values Service (GET /tournament)
   â† tournament.value.json (5KB)

5. Bot Service â†’ Ollama AI
   "Schema + mevcut values + kullanÄ±cÄ± isteÄŸi"
   â† GÃ¼ncellenmiÅŸ JSON (memory: 1024)

6. Bot Service â†’ KullanÄ±cÄ±
   â† GÃ¼ncellenmiÅŸ tournament.value.json
```

**Toplam sÃ¼re**: ~5-8 saniye

---

## Teknik Detaylar

### Docker Compose YapÄ±landÄ±rmasÄ±

**Neden depends_on + healthcheck?**
```yaml
bot-service:
  depends_on:
    ollama:
      condition: service_healthy
```
- Bot service, Ollama hazÄ±r olmadan baÅŸlamaz
- Model indirme sÃ¼resi (~2-3 dakika) beklenir
- Servisler arasÄ± baÄŸÄ±mlÄ±lÄ±k garantilenir

**Neden volume mount?**
```yaml
volumes:
  - ./data/schemas:/data/schemas:ro
```
- `:ro` = read-only, servis dosyalarÄ± deÄŸiÅŸtiremez
- GÃ¼venlik: YanlÄ±ÅŸlÄ±kla ÅŸema silinmesini Ã¶nler
- Hot-reload: Dosya deÄŸiÅŸiklikleri anÄ±nda yansÄ±r

---

## KarÅŸÄ±laÅŸÄ±lan Zorluklar ve Ã‡Ã¶zÃ¼mler

### 1. Ollama Model Ä°ndirme

**Sorun**: Container baÅŸladÄ±ÄŸÄ±nda model yok
```bash
Error: model 'llama3.2:3b' not found
```

**Ã‡Ã¶zÃ¼m**: Entrypoint script ile otomatik indirme
```yaml
command:
  - |
    /bin/ollama serve &
    sleep 10
    ollama pull llama3.2:3b
```

---

### 2. AI YanÄ±tlarÄ±nda TutarsÄ±zlÄ±k

**Sorun**: AI bazen ÅŸu formatÄ± veriyor:
```
"Sure! Here's the updated JSON: {...}"
```

**Ã‡Ã¶zÃ¼m**: 
- Prompta "ONLY JSON" vurgusu
- `json.loads()` ile parse deneme
- Fallback mekanizmasÄ±

---

### 3. Birim DÃ¶nÃ¼ÅŸÃ¼mleri

**Sorun**: KullanÄ±cÄ± "1024mb" diyor, schema "MiB" istiyor

**Ã‡Ã¶zÃ¼m**: AI'a kurallarÄ± aÃ§Ä±kÃ§a belirt
```
- For memory: use MiB (mebibytes) as integer
- "1024mb" â†’ 1024
- "80%" â†’ calculate as milliCPU or ratio
```

---

## Test SenaryolarÄ±

### Test 1: Memory GÃ¼ncellemesi
```bash
curl -X POST http://localhost:5003/message \
  -H "Content-Type: application/json" \
  -d '{"input": "set tournament service memory to 1024mb"}'
```

**Beklenen**: `limitMiB: 1024`

---

### Test 2: Environment Variable
```bash
curl -X POST http://localhost:5003/message \
  -H "Content-Type: application/json" \
  -d '{"input": "set GAME_NAME env to toyblast for matchmaking service"}'
```

**Beklenen**: `envs: {"GAME_NAME": "toyblast"}`

---

### Test 3: CPU Limit (YÃ¼zde)
```bash
curl -X POST http://localhost:5003/message \
  -H "Content-Type: application/json" \
  -d '{"input": "lower cpu limit of chat service to 80%"}'
```

**Beklenen**: `limitMilliCPU: 1200` (1500'Ã¼n %80'i)

---

## Gelecek Ä°yileÅŸtirmeler

1. **Schema Validation**: JSON Schema ile response validation
2. **Caching**: Tekrarlayan istekler iÃ§in Redis cache
3. **Monitoring**: Prometheus + Grafana ile metrik toplama
4. **Rate Limiting**: API abuse'i Ã¶nlemek iÃ§in
5. **Authentication**: API key bazlÄ± auth sistemi

---

## Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### Gereksinimler
- Docker & Docker Compose
- En az 8GB RAM (Ollama iÃ§in)
- 5GB disk alanÄ± (model iÃ§in)

### BaÅŸlatma
```bash
docker compose up --build
```

**Ä°lk baÅŸlatma**: ~5 dakika (model indirme)
**Sonraki baÅŸlatmalar**: ~30 saniye

---

## SonuÃ§

Bu proje, **AI ve mikroservis mimarisini** birleÅŸtirerek karmaÅŸÄ±k JSON konfigÃ¼rasyonlarÄ±nÄ± **basit doÄŸal dil** ile yÃ¶netmeyi saÄŸlÄ±yor. Llama 3.2 modeli sayesinde local ve hÄ±zlÄ± Ã§alÄ±ÅŸan, Docker Compose ile kolayca deploy edilebilen bir sistem oluÅŸturduk.

**Ã–ÄŸrendiklerim**:
- LLM prompt engineering
- Mikroservis arasÄ± iletiÅŸim
- Docker Compose orchestration
- JSON Schema validation

---

**Proje Sahibi**: NurÅŸen Akay  

```

**Kaydet:** `Cmd + S`

---

## ğŸ¯ **ADIM 7: SON KONTROL**

Åu an proje yapÄ±sÄ± ÅŸÃ¶yle olmalÄ±:
```
intern-homework-master/
â”œâ”€â”€ bot-server/
â”‚   â”œâ”€â”€ app.py              âœ…
â”‚   â”œâ”€â”€ Dockerfile          âœ…
â”‚   â””â”€â”€ requirements.txt    âœ…
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ schemas/           âœ… (zaten vardÄ±)
â”‚   â””â”€â”€ values/            âœ… (zaten vardÄ±)
â”œâ”€â”€ schema-server/
â”‚   â”œâ”€â”€ app.py              âœ…
â”‚   â”œâ”€â”€ Dockerfile          âœ…
â”‚   â””â”€â”€ requirements.txt    âœ…
â”œâ”€â”€ values-server/
â”‚   â”œâ”€â”€ app.py              âœ…
â”‚   â”œâ”€â”€ Dockerfile          âœ…
â”‚   â””â”€â”€ requirements.txt    âœ…
â”œâ”€â”€ docker-compose.yml      âœ…
â”œâ”€â”€ INTERN.md               âœ…
â””â”€â”€ README.md               âœ… (zaten vardÄ±)

